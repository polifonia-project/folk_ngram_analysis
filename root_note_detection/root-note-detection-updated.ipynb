{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# loading libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-09T14:58:37.470461Z","iopub.execute_input":"2022-06-09T14:58:37.470906Z","iopub.status.idle":"2022-06-09T14:58:38.492261Z","shell.execute_reply.started":"2022-06-09T14:58:37.470819Z","shell.execute_reply":"2022-06-09T14:58:38.491478Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Reading Dataset","metadata":{}},{"cell_type":"code","source":"# reading the annotated dataset\ndf = pd.read_csv('../input/clean-root-detection-latest/cre_clean_root_detection_NOTE_NUMS_latest.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:29.919337Z","iopub.execute_input":"2022-06-09T15:00:29.919793Z","iopub.status.idle":"2022-06-09T15:00:29.932795Z","shell.execute_reply.started":"2022-06-09T15:00:29.919758Z","shell.execute_reply":"2022-06-09T15:00:29.932150Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"#1- Checking Missing Values\nmissing_data = pd.DataFrame({'total_missing': df.isnull().sum(), 'perc_missing': (df.isnull().sum()/82790)*100})\nmissing_data","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:33.733935Z","iopub.execute_input":"2022-06-09T15:00:33.734377Z","iopub.status.idle":"2022-06-09T15:00:33.750269Z","shell.execute_reply.started":"2022-06-09T15:00:33.734336Z","shell.execute_reply":"2022-06-09T15:00:33.749619Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Handling Missing Values (freq note, freq weighted acc\t)\ndf['freq note'].fillna(df['freq note'].mode()[0], inplace = True)\ndf['freq weighted acc'].fillna(df['freq weighted acc'].mode()[0], inplace = True)\n# finding if there is any null value\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:36.278350Z","iopub.execute_input":"2022-06-09T15:00:36.278609Z","iopub.status.idle":"2022-06-09T15:00:36.288544Z","shell.execute_reply.started":"2022-06-09T15:00:36.278568Z","shell.execute_reply":"2022-06-09T15:00:36.287778Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Exploring 'expert assigned' variable\ndf['expert assigned'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:39.425147Z","iopub.execute_input":"2022-06-09T15:00:39.425417Z","iopub.status.idle":"2022-06-09T15:00:39.432335Z","shell.execute_reply.started":"2022-06-09T15:00:39.425389Z","shell.execute_reply":"2022-06-09T15:00:39.431526Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Cohen Kappa Score computation","metadata":{}},{"cell_type":"code","source":"# we dont want to include ('title', 'certainty', 'root') in the analysis, therefore, we want to remove it\nnewDf = df.drop(['title', 'certainty', 'root'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:48.344166Z","iopub.execute_input":"2022-06-09T15:00:48.344703Z","iopub.status.idle":"2022-06-09T15:00:48.350406Z","shell.execute_reply.started":"2022-06-09T15:00:48.344663Z","shell.execute_reply":"2022-06-09T15:00:48.349701Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n# Calling DataFrame constructor  \narr = []\nfor item in newDf:\n    col = []\n    for item2 in newDf:\n        col.append(cohen_kappa_score(newDf[item], newDf[item2]))\n    arr.append(col)\n    \nmydf = pd.DataFrame(arr)\nmydf = pd.DataFrame(data=mydf.values, columns=newDf.columns)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:51.679417Z","iopub.execute_input":"2022-06-09T15:00:51.680045Z","iopub.status.idle":"2022-06-09T15:00:51.819998Z","shell.execute_reply.started":"2022-06-09T15:00:51.680004Z","shell.execute_reply":"2022-06-09T15:00:51.819319Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Cohen Kappa Correlation","metadata":{}},{"cell_type":"code","source":"import seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\nplt.clf()\nax = fig.add_subplot(111)\nax.set_aspect(1)\nres = sns.heatmap(mydf.values, annot=True, fmt='.2f', cmap=\"YlGnBu\", vmin=0.0, vmax=1.0)\nplt.title('Cohen Kappa Score',fontsize=12)\n\nplt.xticks([i+0.5 for i in range(mydf.values.shape[0])], [str(element) for element in mydf])\nplt.xticks(rotation=90)\n\nplt.yticks([i+0.5 for i in range(mydf.values.shape[1])], [str(element) for element in mydf])\nplt.yticks(rotation=0)\n\nplt.savefig(\"Cohen Kappa Correlation.pdf\", bbox_inches='tight', dpi=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:00:55.061106Z","iopub.execute_input":"2022-06-09T15:00:55.061352Z","iopub.status.idle":"2022-06-09T15:00:56.637369Z","shell.execute_reply.started":"2022-06-09T15:00:55.061325Z","shell.execute_reply":"2022-06-09T15:00:56.636511Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# GLOBAL SETTINGS","metadata":{}},{"cell_type":"code","source":"#FEATURE VECTOR SETTINGS => This will allow us to add/drop (1/0) certain features for classification \nKrumhansl_Shmuckler = 1 \nsimple_weights = 1\nAarden_Essen = 1 \nBellman_Budge = 1\nTemperly_Kostka_Payne = 1  \nas_transcribed = 1 \nfinal_note = 1 \nfreq_note = 1 \nfreq_weighted_acc = 1\ncertainty = 0 # Removing this due to low correlation\nroot = 0 # this was removed upon Danny's suggetion [Dont know what it is??]","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:01:05.566144Z","iopub.execute_input":"2022-06-09T15:01:05.566450Z","iopub.status.idle":"2022-06-09T15:01:05.571757Z","shell.execute_reply.started":"2022-06-09T15:01:05.566416Z","shell.execute_reply":"2022-06-09T15:01:05.570903Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Defining X (features) and Y (target Class)","metadata":{}},{"cell_type":"code","source":"#X = df.drop(['expert assigned'], axis=1)  \nX = df.drop(['expert assigned', 'title'], axis=1)\n\nif(Krumhansl_Shmuckler !=  1):\n    X = X.drop(['Krumhansl-Shmuckler'], axis=1)\nif(simple_weights !=  1):\n    X = X.drop(['simple weights'], axis=1)\nif(Aarden_Essen !=  1):\n    X = X.drop(['Aarden Essen'], axis=1)\nif(Bellman_Budge !=  1):\n    X = X.drop(['Bellman Budge'], axis=1)\nif(Temperly_Kostka_Payne !=  1):  \n    X = X.drop(['Temperly Kostka Payne'], axis=1)\nif(as_transcribed !=  1):\n    X = X.drop(['as transcribed'], axis=1)\nif(final_note !=  1):\n    X = X.drop(['final_note'], axis=1)\nif(freq_note !=  1):\n    X = X.drop(['freq note'], axis=1)\nif(freq_weighted_acc !=  1):\n    X = X.drop(['freq weighted acc'], axis=1)\nif(certainty !=  1):\n    X = X.drop(['certainty'], axis=1)    \nif(root !=  1):\n    X = X.drop(['root'], axis=1)\n    \nprint(\"List of features considered: \", X.columns)\n\ny = df['expert assigned']","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:01:12.118021Z","iopub.execute_input":"2022-06-09T15:01:12.118546Z","iopub.status.idle":"2022-06-09T15:01:12.134848Z","shell.execute_reply.started":"2022-06-09T15:01:12.118513Z","shell.execute_reply":"2022-06-09T15:01:12.134062Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Taking 10% of the data out from the original to evluate the performance of the developed model","metadata":{}},{"cell_type":"code","source":"# split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\nModelDataset_X, EvalationDataset_X, ModelDataset_y, EvalationDataset_y = train_test_split(X, y, test_size = 0.1, random_state = 30)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:01:17.037314Z","iopub.execute_input":"2022-06-09T15:01:17.037675Z","iopub.status.idle":"2022-06-09T15:01:17.058977Z","shell.execute_reply.started":"2022-06-09T15:01:17.037645Z","shell.execute_reply":"2022-06-09T15:01:17.058310Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(ModelDataset_y.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:01:21.174463Z","iopub.execute_input":"2022-06-09T15:01:21.174745Z","iopub.status.idle":"2022-06-09T15:01:21.183515Z","shell.execute_reply.started":"2022-06-09T15:01:21.174715Z","shell.execute_reply":"2022-06-09T15:01:21.182867Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import RandomOverSampler\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:01:23.902391Z","iopub.execute_input":"2022-06-09T15:01:23.902918Z","iopub.status.idle":"2022-06-09T15:01:24.338021Z","shell.execute_reply.started":"2022-06-09T15:01:23.902891Z","shell.execute_reply":"2022-06-09T15:01:24.337243Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n# Preparing dataset for Model Creation (It is kind of training dataet)\n# first random sampling\noversample = RandomOverSampler(sampling_strategy='minority')\nModelDataset_X_oversample, ModelDataset_y_oversample = oversample.fit_resample(ModelDataset_X, ModelDataset_y)   \nprint( ModelDataset_y_oversample.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:01:26.335632Z","iopub.execute_input":"2022-06-09T15:01:26.335897Z","iopub.status.idle":"2022-06-09T15:01:26.346955Z","shell.execute_reply.started":"2022-06-09T15:01:26.335869Z","shell.execute_reply":"2022-06-09T15:01:26.346497Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\nsmt = SMOTE()\nModelDataset_X_smote, ModelDataset_y_smote = smt.fit_resample(ModelDataset_X_oversample, ModelDataset_y_oversample)\n\nprint( ModelDataset_y_smote.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:02:48.813953Z","iopub.execute_input":"2022-06-09T15:02:48.814639Z","iopub.status.idle":"2022-06-09T15:02:48.834503Z","shell.execute_reply.started":"2022-06-09T15:02:48.814605Z","shell.execute_reply":"2022-06-09T15:02:48.833797Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Datasets for experimentations","metadata":{}},{"cell_type":"code","source":"\n# Preparing dataset for Model Evaluation (It is kind of test dataet)\n# first random sampling\noversample = RandomOverSampler(sampling_strategy='minority')\nEvalationDataset_X_oversample, EvalationDataset_y_oversample = oversample.fit_resample(EvalationDataset_X, EvalationDataset_y)\n    \n# Counting Unique values of each class after random sampling\n#smt = SMOTE()\nEvalationDataset_X_smote, EvalationDataset_y_smote = smt.fit_resample(EvalationDataset_X_oversample, EvalationDataset_y_oversample)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:02:53.286740Z","iopub.execute_input":"2022-06-09T15:02:53.287623Z","iopub.status.idle":"2022-06-09T15:02:53.309048Z","shell.execute_reply.started":"2022-06-09T15:02:53.287561Z","shell.execute_reply":"2022-06-09T15:02:53.308306Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# At this point we have the following datasets\n\n(ModelDataset_X, ModelDataset_y)\n(EvalationDataset_X, EvalationDataset_y)\n\n(ModelDataset_X_smote, ModelDataset_y_smote)\n(EvalationDataset_X_smote, EvalationDataset_y_smote)","metadata":{}},{"cell_type":"code","source":"\n# count unique values of each class\n#print(\"count unique values of each class - ModelDataset_y\")\n#print(ModelDataset_y.value_counts())\nModelDataset_y_s = ModelDataset_y.value_counts()\n\n#print(\"count unique values of each class - ModelDataset_y_smote\") \n#print(ModelDataset_y_smote.value_counts())\nModelDataset_y_smote_s = ModelDataset_y_smote.value_counts()\n\n#print(\"count unique values of each class - EvalationDataset_y\") \n#print(EvalationDataset_y.value_counts())\nEvalationDataset_y_s = EvalationDataset_y.value_counts()\n\n#print(\"count unique values of each class - EvalationDataset_y_smote\") \n#print(EvalationDataset_y_smote.value_counts())\nEvalationDataset_y_smote_s = EvalationDataset_y_smote.value_counts()\n\nmydf1 = pd.DataFrame({'note':ModelDataset_y_s.index, 'count':ModelDataset_y_s.values})\nmydf2 = pd.DataFrame({'note':ModelDataset_y_smote_s.index, 'count':ModelDataset_y_smote_s.values})\nmydf3 = pd.DataFrame({'note':EvalationDataset_y_s.index, 'count':EvalationDataset_y_s.values})\nmydf4 = pd.DataFrame({'note':EvalationDataset_y_smote_s.index, 'count':EvalationDataset_y_smote_s.values})\n\nmydf1 = mydf1.convert_dtypes(int)\nmydf2 = mydf2.convert_dtypes(int)\nmydf3 = mydf3.convert_dtypes(int)\nmydf4 = mydf4.convert_dtypes(int)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:02:57.921828Z","iopub.execute_input":"2022-06-09T15:02:57.922816Z","iopub.status.idle":"2022-06-09T15:02:57.938634Z","shell.execute_reply.started":"2022-06-09T15:02:57.922762Z","shell.execute_reply":"2022-06-09T15:02:57.937738Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of model and evaluation datasets","metadata":{}},{"cell_type":"code","source":"mdf = pd.concat([mydf1, mydf2, mydf3, mydf4], axis=1,  keys=('ModelDataset_y','ModelDataset_y_smote', \"EvalationDataset_y\", \"EvalationDataset_y_smote\"))\nmdf","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:03:01.908554Z","iopub.execute_input":"2022-06-09T15:03:01.909208Z","iopub.status.idle":"2022-06-09T15:03:01.928510Z","shell.execute_reply.started":"2022-06-09T15:03:01.909175Z","shell.execute_reply":"2022-06-09T15:03:01.927826Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Classification report of state-of-the-art models for root note detection ","metadata":{}},{"cell_type":"code","source":"\nprint(\"Classification Report - Krumhansl-Shmuckler\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X[\"Krumhansl-Shmuckler\"], labels=[0,2,4,7,9]))\n\nprint(\"Classification Report - simple weights\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X[\"simple weights\"], labels=[0,2,4,7,9]))\n\nprint(\"Classification Report - Aarden Essen\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X[\"Aarden Essen\"], labels=[0,2,4,7,9]))\n\nprint(\"Classification Report - Bellman Budge\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X[\"Bellman Budge\"], labels=[0,2,4,7,9]))\n\nprint(\"Classification Report - Temperly Kostka Payne\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X[\"Temperly Kostka Payne\"], labels=[0,2,4,7,9]))\n\n\nprint(\"Classification Report - as transcribed\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X['as transcribed'], labels=[0,2,4,7,9]))\n\n\nprint(\"Classification Report - 'final_note'\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X['final_note'], labels=[0,2,4,7,9]))\n\n\nprint(\"Classification Report - 'freq note'\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X['freq note'], labels=[0,2,4,7,9]))\n\nprint(\"Classification Report - 'freq weighted acc'\")\nprint(classification_report(EvalationDataset_y, EvalationDataset_X['freq weighted acc'], labels=[0,2,4,7,9]))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:03:08.619454Z","iopub.execute_input":"2022-06-09T15:03:08.620005Z","iopub.status.idle":"2022-06-09T15:03:08.663287Z","shell.execute_reply.started":"2022-06-09T15:03:08.619976Z","shell.execute_reply":"2022-06-09T15:03:08.662347Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Factorial Design Experimental Setup\n**Grid-based hyperparameter tuning for developing the optimized model**","metadata":{}},{"cell_type":"code","source":"# import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# import Random Forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n# train a Gaussian Naive Bayes classifier on the training set\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\n\nsvm_param_grid = {\n             'C': [0.1, 0.5, 1.0],\n             'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n             'degree': [2, 3, 5],\n             'gamma': ['auto', 'scale'],\n             'tol': [1e-5, 1e-3, 1e-2],\n             'max_iter': [-1, 5, 10]\n}\n\nRandomForest_param_grid = {\n    'max_depth': [2, 3, 4, 5, 9, 10, 11,12, 15, 20, 22, 23, 30, 60],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 25],\n    'criterion': ['gini', 'entropy'],\n}\n\n\nDecisionTree_param_grid = {\n    'max_depth': [2, 3, 4, 5, 10, 15, 30, 60],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'criterion': ['gini', 'entropy'],\n}\n\nNB_param_grid = {\n                'var_smoothing': np.logspace(0,-9, num=100)\n                }\n\n\nmodel_param = {\n  'DecisionTree':{\n      'model': DecisionTreeClassifier(),\n      'params': DecisionTree_param_grid,\n  },\n    \n  'RandomForest': {\n          'model': RandomForestClassifier(),\n          'params': RandomForest_param_grid,\n    },\n    \n  'NB': {\n          'model': GaussianNB(),\n          'params': NB_param_grid,\n    },\n   \n  #'SVM': {\n  #         'model':   svm.SVC(),\n  #         'params': svm_param_grid,    \n  # }    \n}","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:03:15.662866Z","iopub.execute_input":"2022-06-09T15:03:15.663112Z","iopub.status.idle":"2022-06-09T15:03:15.674992Z","shell.execute_reply.started":"2022-06-09T15:03:15.663086Z","shell.execute_reply":"2022-06-09T15:03:15.674303Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# function to be called for evaluating each model defined above\ndef getBestModel (X, y):\n    results = []\n    for model, param in model_param.items():\n        clf = GridSearchCV(param['model'], param['params'], cv= 10, scoring='f1_macro')\n        clf.fit(X, y.ravel())\n        results.append(\n                            {\n                            'model': param['model'],\n                            'best_score': clf.best_score_,\n                            'best_params': clf.best_params_,\n                            }\n                      )\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:03:19.828813Z","iopub.execute_input":"2022-06-09T15:03:19.829294Z","iopub.status.idle":"2022-06-09T15:03:19.838110Z","shell.execute_reply.started":"2022-06-09T15:03:19.829263Z","shell.execute_reply":"2022-06-09T15:03:19.837355Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# The following experimentation should be exectued twice \n\n1. **with `as transcribe` feature**\n1. **without `as transcribe` feature** ","metadata":{}},{"cell_type":"markdown","source":"# Factorial Design Experiment - GridSearch - Implementation\n# finding best models on orgininal dataset (ModelDataset_X, ModelDataset_y)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n#ModelDataset_X, ModelDataset_y,\n#ModelDataset_X_smote, ModelDataset_y_smote,\n#EvalationDataset_X, EvalationDataset_y,\n#EvalationDataset_X_smote, EvalationDataset_y_smote\nresults = getBestModel(ModelDataset_X, ModelDataset_y)\n\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:03:31.980672Z","iopub.execute_input":"2022-06-09T15:03:31.981125Z","iopub.status.idle":"2022-06-09T15:32:16.200439Z","shell.execute_reply.started":"2022-06-09T15:03:31.981088Z","shell.execute_reply":"2022-06-09T15:32:16.199735Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# loading best models of DecisionTree, RandomForest, and GaussianNB","metadata":{}},{"cell_type":"code","source":"result1 = pd.DataFrame(results)\nresult1.sort_values(by='best_score',ascending=False, inplace=True)\nresult1","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:32:27.866108Z","iopub.execute_input":"2022-06-09T15:32:27.866427Z","iopub.status.idle":"2022-06-09T15:32:27.882512Z","shell.execute_reply.started":"2022-06-09T15:32:27.866389Z","shell.execute_reply":"2022-06-09T15:32:27.881770Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# the static indices are used based on the above results\nbestModel_DecisionTreeClassifier = results[0]['model']\nbestModel_RandomForestClassifier = results[1]['model']\nbestModel_GaussianNB = results[2]['model']","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:33:07.695559Z","iopub.execute_input":"2022-06-09T15:33:07.695844Z","iopub.status.idle":"2022-06-09T15:33:07.700143Z","shell.execute_reply.started":"2022-06-09T15:33:07.695813Z","shell.execute_reply":"2022-06-09T15:33:07.699521Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Fitting the best models\n**priting its classification report for further analysis**","metadata":{}},{"cell_type":"code","source":"bestModel_DecisionTreeClassifier.fit(ModelDataset_X, ModelDataset_y.ravel())\nbestModel_RandomForestClassifier.fit(ModelDataset_X, ModelDataset_y.ravel())\nbestModel_GaussianNB.fit(ModelDataset_X, ModelDataset_y.ravel())\n\nprint(bestModel_RandomForestClassifier)\nprint(bestModel_DecisionTreeClassifier)\nprint(bestModel_GaussianNB)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:33:12.550653Z","iopub.execute_input":"2022-06-09T15:33:12.550905Z","iopub.status.idle":"2022-06-09T15:33:12.730366Z","shell.execute_reply.started":"2022-06-09T15:33:12.550878Z","shell.execute_reply":"2022-06-09T15:33:12.729632Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Best models evaluation on unseen dataset (EvalationDataset_X and EvalationDataset_X_smote)","metadata":{}},{"cell_type":"code","source":"# apply the model\nEvalationDataset_y_pred = bestModel_RandomForestClassifier.predict(EvalationDataset_X)\nprint(classification_report(EvalationDataset_y, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\nEvalationDataset_y_pred = bestModel_RandomForestClassifier.predict(EvalationDataset_X_smote)\nprint(classification_report(EvalationDataset_y_smote, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\n\n\nEvalationDataset_y_pred = bestModel_DecisionTreeClassifier.predict(EvalationDataset_X)\nprint(classification_report(EvalationDataset_y, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\nEvalationDataset_y_pred = bestModel_DecisionTreeClassifier.predict(EvalationDataset_X_smote)\nprint(classification_report(EvalationDataset_y_smote, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\n\nEvalationDataset_y_pred = bestModel_GaussianNB.predict(EvalationDataset_X)\nprint(classification_report(EvalationDataset_y, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\nEvalationDataset_y_pred = bestModel_GaussianNB.predict(EvalationDataset_X_smote)\nprint(classification_report(EvalationDataset_y_smote, EvalationDataset_y_pred, labels=[0,2,4,7,9]))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:33:21.824168Z","iopub.execute_input":"2022-06-09T15:33:21.824424Z","iopub.status.idle":"2022-06-09T15:33:21.883328Z","shell.execute_reply.started":"2022-06-09T15:33:21.824398Z","shell.execute_reply":"2022-06-09T15:33:21.882627Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"EvalationDataset_y\nprint(\"count unique values of each class - EvalationDataset_y\") \nprint(EvalationDataset_y.value_counts())\n\n\nprint(\"count unique values of each class - EvalationDataset_y_smote\") \nprint(EvalationDataset_y_smote.value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:33:49.458357Z","iopub.execute_input":"2022-06-09T15:33:49.458685Z","iopub.status.idle":"2022-06-09T15:33:49.466931Z","shell.execute_reply.started":"2022-06-09T15:33:49.458650Z","shell.execute_reply":"2022-06-09T15:33:49.466376Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Factorial Design Experiment - GridSearch - Implementation\n**finding best models on balanced dataset (ModelDataset_X_smote, ModelDataset_y_smote)**","metadata":{}},{"cell_type":"code","source":"my_results = getBestModel(ModelDataset_X_smote, ModelDataset_y_smote)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:35:37.909152Z","iopub.execute_input":"2022-06-09T15:35:37.909623Z","iopub.status.idle":"2022-06-09T16:17:34.244125Z","shell.execute_reply.started":"2022-06-09T15:35:37.909562Z","shell.execute_reply":"2022-06-09T16:17:34.243362Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(my_results)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T16:24:32.171265Z","iopub.execute_input":"2022-06-09T16:24:32.171955Z","iopub.status.idle":"2022-06-09T16:24:32.177175Z","shell.execute_reply.started":"2022-06-09T16:24:32.171914Z","shell.execute_reply":"2022-06-09T16:24:32.176633Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"my_results1 = pd.DataFrame(my_results)\nmy_results1.sort_values(by='best_score',ascending=False, inplace=True)\nmy_results1","metadata":{"execution":{"iopub.status.busy":"2022-06-09T16:23:56.609532Z","iopub.execute_input":"2022-06-09T16:23:56.609839Z","iopub.status.idle":"2022-06-09T16:23:56.674604Z","shell.execute_reply.started":"2022-06-09T16:23:56.609799Z","shell.execute_reply":"2022-06-09T16:23:56.673870Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Best models based on previous results","metadata":{}},{"cell_type":"code","source":"bestModel_s_DecisionTreeClassifier = my_results[0]['model']\nbestModel_s_RandomForestClassifier = my_results[1]['model']\nbestModel_s_GaussianNB = my_results[2]['model']","metadata":{"execution":{"iopub.status.busy":"2022-06-09T16:25:21.920891Z","iopub.execute_input":"2022-06-09T16:25:21.921160Z","iopub.status.idle":"2022-06-09T16:25:21.925388Z","shell.execute_reply.started":"2022-06-09T16:25:21.921132Z","shell.execute_reply":"2022-06-09T16:25:21.924636Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"bestModel_s_DecisionTreeClassifier.fit(ModelDataset_X_smote, ModelDataset_y_smote.ravel())\nbestModel_s_RandomForestClassifier.fit(ModelDataset_X_smote, ModelDataset_y_smote.ravel())\nbestModel_s_GaussianNB.fit(ModelDataset_X_smote, ModelDataset_y_smote.ravel())\n\nprint(bestModel_s_DecisionTreeClassifier)\nprint(bestModel_s_RandomForestClassifier)\nprint(bestModel_s_GaussianNB)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T16:25:33.547673Z","iopub.execute_input":"2022-06-09T16:25:33.547921Z","iopub.status.idle":"2022-06-09T16:25:33.843107Z","shell.execute_reply.started":"2022-06-09T16:25:33.547895Z","shell.execute_reply":"2022-06-09T16:25:33.842306Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Best models evaluation on unseen dataset (EvalationDataset_X and EvalationDataset_X_smote)","metadata":{}},{"cell_type":"code","source":"print(\"Randomforest - Classifier\")\n\nEvalationDataset_y_pred = bestModel_s_RandomForestClassifier.predict(EvalationDataset_X)\nprint(classification_report(EvalationDataset_y, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\nEvalationDataset_y_pred = bestModel_s_RandomForestClassifier.predict(EvalationDataset_X_smote)\nprint(classification_report(EvalationDataset_y_smote, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\n\nprint(\"Decision Tree - Classifier\")\nEvalationDataset_y_pred = bestModel_s_DecisionTreeClassifier.predict(EvalationDataset_X)\nprint(classification_report(EvalationDataset_y, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\nEvalationDataset_y_pred = bestModel_s_DecisionTreeClassifier.predict(EvalationDataset_X_smote)\nprint(classification_report(EvalationDataset_y_smote, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\n\n\nprint(\"Naive Bayes - Classifier\")\nEvalationDataset_y_pred = bestModel_s_GaussianNB.predict(EvalationDataset_X)\nprint(classification_report(EvalationDataset_y, EvalationDataset_y_pred, labels=[0,2,4,7,9]))\nEvalationDataset_y_pred = bestModel_s_GaussianNB.predict(EvalationDataset_X_smote)\nprint(classification_report(EvalationDataset_y_smote, EvalationDataset_y_pred, labels=[0,2,4,7,9]))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T16:26:23.318957Z","iopub.execute_input":"2022-06-09T16:26:23.319225Z","iopub.status.idle":"2022-06-09T16:26:23.380675Z","shell.execute_reply.started":"2022-06-09T16:26:23.319195Z","shell.execute_reply":"2022-06-09T16:26:23.379982Z"},"trusted":true},"execution_count":42,"outputs":[]}]}