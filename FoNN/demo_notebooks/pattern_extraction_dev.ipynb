{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Working notebook for FoNN pattern extraction tools\n",
    "# Currently setting up data inputs for similarity experiment 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# imports\n",
    "from FoNN.pattern_extraction import NgramPatternCorpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: Setup NgramPatternCorpus class instance to extract and store patterns from feature sequence data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading input data: 100%|██████████| 315/315 [00:00<00:00, 1546.73it/s]\n",
      "Formatting data: 100%|██████████| 315/315 [00:00<00:00, 553500.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define paths\n",
    "# 'in_dir' must point to a directory of feature sequence data csv files extracted from the corpus via feature_extraction_demo.ipynb.\n",
    "inpath = '//Users/dannydiamond/NUIG/Polifonia/thesession/exp3_test_data/incipit_and_cadence/feature_sequence_data/accent'\n",
    "outpath = '/Users/dannydiamond/NUIG/Polifonia/thesession/exp3_test_data/incipit_and_cadence/pattern_corpus/accent'\n",
    "# set n_vals variable as tuple containing min and max pattern lengths for which patterns will be extracted\n",
    "n_vals = (3, 12)\n",
    "# Note: as above, maximum range is 3-12 pattern elements. If only a single pattern length is under investigation, the tuple still requires two elements, per (4, 4) for 4-element patterns.\n",
    "\n",
    "# setup NgramPatternCorpus instance for MTC-ANN corpus:\n",
    "\n",
    "# Args:\n",
    "# 'in_dir' and 'out_dir' -- map to in and out paths defined above.\n",
    "# 'feature' -- the target musical feature for which patterns will be extracted.\n",
    "# 16 features are available; names of all feature are accessible by reading NgramPatternCorpus.FEATURES, are listed in ./README.md, and in feature_extraction_tools.py docstring.\n",
    "\n",
    "# In this example we are extracting duration-weighted note-level diatonic scale degree patterns from the MTC-ANN corpus.\n",
    "mtc_ann_pattern_corpus = NgramPatternCorpus(in_dir=inpath, out_dir=outpath, feature='diatonic_scale_degree', n_vals=n_vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract all tune titles from corpus, store as NgramPatternCorpus.titles attr, and write to file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# save tune titles to 'titles' attr and write to file\n",
    "mtc_ann_pattern_corpus.save_tune_titles_to_file()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-step call to perform two related tasks:\n",
    "1. Extract all n-gram patterns between 3-12 elements in length which occur at least once in the corpus. Store as NgramPatternCorpus.patterns attr and write to file.\n",
    "2. Count occurrences of these patterns in all tunes in corpus and store in a sparse matrix as NgramPatternCorpus.pattern_freq_matrix and write to file.\n",
    "attr."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# extract all patterns via n-grams; populate pattern occurrences matrix, save both to file\n",
    "mtc_ann_pattern_corpus.create_pattern_frequency_matrix(write_output=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print corpus info: (via custom NgramPatternCorpus.__repr__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus name: incipit_and_cadence\n",
      "Level: accent-level\n",
      "Input directory: //Users/dannydiamond/NUIG/Polifonia/thesession/exp3_test_data/incipit_and_cadence/feature_sequence_data/accent\n",
      "Corpus contains 315 tunes.\n",
      "Number of patterns extracted: 61326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print corpus info\n",
    "print(mtc_ann_pattern_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform pattern occurrence counts in NgramPatternCorpus.pattern_freq_matrix into TF-IDF values. Store the output matrix as NgramPatternCorpus.pattern_tfidf_matrix attr and write to file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "mtc_ann_pattern_corpus.calculate_tfidf_vals(write_output=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final step: precalculate the \"TFIDF\" similarity metric: create a pairwise Cosine similarity matrix between the pattern TF-IDF vectors of all tunes in the corpus, and write output to file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "mtc_ann_pattern_corpus.calculate_tfidf_vector_cos_similarity()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: All files outputted via pattern extraction pipeline are stored in automatically-generated ```./pattern_corpus``` dir under the corpus root dir. They are input requirements for the similarity search tools in FoNN.similarity_search.PatternSimilarity class, which are illustrated in similarity_search_demo.ipynb notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}