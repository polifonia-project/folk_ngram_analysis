{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Demo notebook for FoNN similarity search tools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "\n",
    "from FoNN.similarity_search import TFIDFSimilarity, IncipitAndCadenceSimilarity, MotifSimilarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# set input corpus path\n",
    "mtc_ann_corpus_path = '../mtc_ann_corpus'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Done.\n",
      "Loading patterns...\n",
      "Done.\n",
      "Loading pattern occurrences matrix...\n",
      "Done.\n",
      "Loading pattern TF-IDF matrix...\n",
      "Done.\n",
      "Running single-weighted 'motif' similarity search...\n",
      "Median: 0.1789622807553229\n",
      "Max: 0.1789622807553229\n",
      "Median absolute deviation: 0.0\n",
      "Threshold: 0.1789622807553229\n",
      "21 search term patterns extracted:\n",
      "21 exact matches detected\n",
      "7 very similar patterns detected.\n",
      "28 similar patterns detected.\n",
      "Final single-weighted 'motif' results:\n",
      "              score  normalized_score\n",
      "title                                \n",
      "NLB072311_01    8.5             1.000\n",
      "NLB070089_01    6.5             0.733\n",
      "NLB070732_01    4.0             0.400\n",
      "NLB070096_01    3.0             0.267\n",
      "NLB070053_01    3.0             0.267\n",
      "NLB073486_01    3.0             0.267\n",
      "NLB073339_01    2.5             0.200\n",
      "NLB075167_01    2.5             0.200\n",
      "NLB072553_01    2.5             0.200\n",
      "NLB074104_01    2.0             0.133\n",
      "NLB074769_02    2.0             0.133\n",
      "NLB075532_01    2.0             0.133\n",
      "NLB073333_01    2.0             0.133\n",
      "NLB073990_01    2.0             0.133\n",
      "NLB075616_01    2.0             0.133\n",
      "NLB076495_01    2.0             0.133\n",
      "NLB070693_01    2.0             0.133\n",
      "NLB071957_03    2.0             0.133\n",
      "NLB141649_01    1.5             0.067\n",
      "NLB074342_01    1.0             0.000\n",
      "NLB074470_01    1.0             0.000\n",
      "NLB072624_01    1.0             0.000\n",
      "NLB075063_01    1.0             0.000\n",
      "NLB073991_02    1.0             0.000\n",
      "NLB074533_01    1.0             0.000\n",
      "NLB072708_01    1.0             0.000\n",
      "NLB143240_01    1.0             0.000\n",
      "NLB072567_01    1.0             0.000\n",
      "NLB075184_01    1.0             0.000\n",
      "NLB073750_01    1.0             0.000\n",
      "NLB074938_01    1.0             0.000\n",
      "NLB073426_01    1.0             0.000\n",
      "NLB075074_01    1.0             0.000\n",
      "NLB071014_01    1.0             0.000\n",
      "NLB073639_01    1.0             0.000\n",
      "NLB075742_01    1.0             0.000\n",
      "NLB074754_01    1.0             0.000\n",
      "NLB075525_01    1.0             0.000\n",
      "NLB072559_01    1.0             0.000\n",
      "NLB073588_01    1.0             0.000\n",
      "NLB073709_01    1.0             0.000\n",
      "NLB075379_01    1.0             0.000\n",
      "NLB072587_01    1.0             0.000\n",
      "NLB073771_02    1.0             0.000\n",
      "NLB074552_01    1.0             0.000\n",
      "Running double-weighted 'motif' similarity search...\n",
      "Median: 0.1789622807553229\n",
      "Max: 0.1789622807553229\n",
      "Median absolute deviation: 0.0\n",
      "Threshold: 0.1789622807553229\n",
      "21 search term patterns extracted:\n",
      "21 exact matches detected\n",
      "7 very similar patterns detected.\n",
      "28 similar patterns detected.\n",
      "Final double-weighted 'motif' results:\n",
      "              score  normalized_score\n",
      "title                                \n",
      "NLB072311_01  1.521             1.000\n",
      "NLB070089_01  1.163             0.733\n",
      "NLB070732_01  0.716             0.400\n",
      "NLB070096_01  0.537             0.267\n",
      "NLB070053_01  0.537             0.267\n",
      "NLB073486_01  0.537             0.267\n",
      "NLB073339_01  0.447             0.200\n",
      "NLB075167_01  0.447             0.200\n",
      "NLB072553_01  0.447             0.200\n",
      "NLB074104_01  0.358             0.133\n",
      "NLB074769_02  0.358             0.133\n",
      "NLB075532_01  0.358             0.133\n",
      "NLB073333_01  0.358             0.133\n",
      "NLB073990_01  0.358             0.133\n",
      "NLB075616_01  0.358             0.133\n",
      "NLB076495_01  0.358             0.133\n",
      "NLB070693_01  0.358             0.133\n",
      "NLB071957_03  0.358             0.133\n",
      "NLB141649_01  0.268             0.066\n",
      "NLB074342_01  0.179             0.000\n",
      "NLB074470_01  0.179             0.000\n",
      "NLB072624_01  0.179             0.000\n",
      "NLB075063_01  0.179             0.000\n",
      "NLB073991_02  0.179             0.000\n",
      "NLB074533_01  0.179             0.000\n",
      "NLB072708_01  0.179             0.000\n",
      "NLB143240_01  0.179             0.000\n",
      "NLB072567_01  0.179             0.000\n",
      "NLB075184_01  0.179             0.000\n",
      "NLB073750_01  0.179             0.000\n",
      "NLB074938_01  0.179             0.000\n",
      "NLB073426_01  0.179             0.000\n",
      "NLB075074_01  0.179             0.000\n",
      "NLB071014_01  0.179             0.000\n",
      "NLB073639_01  0.179             0.000\n",
      "NLB075742_01  0.179             0.000\n",
      "NLB074754_01  0.179             0.000\n",
      "NLB075525_01  0.179             0.000\n",
      "NLB072559_01  0.179             0.000\n",
      "NLB073588_01  0.179             0.000\n",
      "NLB073709_01  0.179             0.000\n",
      "NLB075379_01  0.179             0.000\n",
      "NLB072587_01  0.179             0.000\n",
      "NLB073771_02  0.179             0.000\n",
      "NLB074552_01  0.179             0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": "              score  normalized_score\ntitle                                \nNLB072311_01  1.521             1.000\nNLB070089_01  1.163             0.733\nNLB070732_01  0.716             0.400\nNLB070096_01  0.537             0.267\nNLB070053_01  0.537             0.267\nNLB073486_01  0.537             0.267\nNLB073339_01  0.447             0.200\nNLB075167_01  0.447             0.200\nNLB072553_01  0.447             0.200\nNLB074104_01  0.358             0.133\nNLB074769_02  0.358             0.133\nNLB075532_01  0.358             0.133\nNLB073333_01  0.358             0.133\nNLB073990_01  0.358             0.133\nNLB075616_01  0.358             0.133\nNLB076495_01  0.358             0.133\nNLB070693_01  0.358             0.133\nNLB071957_03  0.358             0.133\nNLB141649_01  0.268             0.066\nNLB074342_01  0.179             0.000\nNLB074470_01  0.179             0.000\nNLB072624_01  0.179             0.000\nNLB075063_01  0.179             0.000\nNLB073991_02  0.179             0.000\nNLB074533_01  0.179             0.000\nNLB072708_01  0.179             0.000\nNLB143240_01  0.179             0.000\nNLB072567_01  0.179             0.000\nNLB075184_01  0.179             0.000\nNLB073750_01  0.179             0.000\nNLB074938_01  0.179             0.000\nNLB073426_01  0.179             0.000\nNLB075074_01  0.179             0.000\nNLB071014_01  0.179             0.000\nNLB073639_01  0.179             0.000\nNLB075742_01  0.179             0.000\nNLB074754_01  0.179             0.000\nNLB075525_01  0.179             0.000\nNLB072559_01  0.179             0.000\nNLB073588_01  0.179             0.000\nNLB073709_01  0.179             0.000\nNLB075379_01  0.179             0.000\nNLB072587_01  0.179             0.000\nNLB073771_02  0.179             0.000\nNLB074552_01  0.179             0.000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>normalized_score</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>NLB072311_01</th>\n      <td>1.521</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>NLB070089_01</th>\n      <td>1.163</td>\n      <td>0.733</td>\n    </tr>\n    <tr>\n      <th>NLB070732_01</th>\n      <td>0.716</td>\n      <td>0.400</td>\n    </tr>\n    <tr>\n      <th>NLB070096_01</th>\n      <td>0.537</td>\n      <td>0.267</td>\n    </tr>\n    <tr>\n      <th>NLB070053_01</th>\n      <td>0.537</td>\n      <td>0.267</td>\n    </tr>\n    <tr>\n      <th>NLB073486_01</th>\n      <td>0.537</td>\n      <td>0.267</td>\n    </tr>\n    <tr>\n      <th>NLB073339_01</th>\n      <td>0.447</td>\n      <td>0.200</td>\n    </tr>\n    <tr>\n      <th>NLB075167_01</th>\n      <td>0.447</td>\n      <td>0.200</td>\n    </tr>\n    <tr>\n      <th>NLB072553_01</th>\n      <td>0.447</td>\n      <td>0.200</td>\n    </tr>\n    <tr>\n      <th>NLB074104_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB074769_02</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB075532_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB073333_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB073990_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB075616_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB076495_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB070693_01</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB071957_03</th>\n      <td>0.358</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>NLB141649_01</th>\n      <td>0.268</td>\n      <td>0.066</td>\n    </tr>\n    <tr>\n      <th>NLB074342_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB074470_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB072624_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB075063_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073991_02</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB074533_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB072708_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB143240_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB072567_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB075184_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073750_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB074938_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073426_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB075074_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB071014_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073639_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB075742_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB074754_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB075525_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB072559_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073588_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073709_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB075379_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB072587_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB073771_02</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>NLB074552_01</th>\n      <td>0.179</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize MotifSimilarity class instance to run 'motif' method similarity searches\n",
    "# Args:\n",
    "# -- n -- length of patterns under examination (number of elements). This must correspond to the pattern length outputted via ngram_pattern_extraction_demo.py.\n",
    "# corpus_path -- points to path defined in cell above\n",
    "# level -- the appropriate input data representation level for the input data under investigation. Can be 'note' (note-level), 'accent' (accent-level), or 'duration_weighted' (duration-weighted note-level).\n",
    "# feature -- the musical feature under investigation. For a list of the 16 available features extracted by FoNN's ingest pipeline, see NgramPatternCorpus.FEATURES or ./README.md.\n",
    "motif = MotifSimilarity(n=8, corpus_path=mtc_ann_corpus_path, level='duration_weighted', feature='diatonic_scale_degree')\n",
    "# select query tune (tune id corresponds to input filename, excluding filetype suffix)\n",
    "motif.query_tune='NLB015569_01'\n",
    "# run standard single-weighted implementation (recommended)\n",
    "motif.run_similarity_search(weighting='single')\n",
    "# run alternate double-weighted implementation (recommended)\n",
    "motif.run_similarity_search(weighting='double')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Done.\n",
      "Loading patterns...\n",
      "Done.\n",
      "Extracting incipit and cadence subsequences from feature sequence data...\n",
      "Done.\n",
      "Running 'incipit and cadence' similarity search, using Levenshtein distance metric...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/360 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7275076d172647cbb9abf86273c41b02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Levenshtein distance\n",
      "NLB138219_01                     8\n",
      "NLB072886_01                     9\n",
      "NLB071666_01                    10\n",
      "NLB072886_02                    10\n",
      "NLB072299_01                    12\n",
      "Running 'incipit and cadence' similarity search, using Hamming distance metric...\n",
      "              Hamming distance\n",
      "NLB070089_01          0.302979\n",
      "NLB072311_01          0.363525\n",
      "NLB072946_01          0.424316\n",
      "NLB075635_01          0.515137\n",
      "NLB071957_03          0.515137\n",
      "Running 'incipit and cadence' similarity search, using Weighted Hamming distance metric...\n",
      "              Custom-weighted Hamming distance\n",
      "NLB138219_01                               8.5\n",
      "NLB071666_01                              10.5\n",
      "NLB071441_01                              10.5\n",
      "NLB072886_01                              11.0\n",
      "NLB072299_01                              12.5\n"
     ]
    }
   ],
   "source": [
    "# initialize IncipitAndCadenceSimilarity class instance to run 'incipit and cadence' similarity searches\n",
    "# Args are as above with the exception of 'n', which does not need to be specified for this class.\n",
    "incipit = IncipitAndCadenceSimilarity(corpus_path=mtc_ann_corpus_path, level='duration_weighted', feature='diatonic_scale_degree')\n",
    "# select query tune\n",
    "incipit.query_tune='NLB015569_01'\n",
    "# run standard Levenshtein distance implementation (recommended)\n",
    "incipit.run_similarity_search(edit_dist_metric='levenshtein')\n",
    "# run with alternate Hamming distance implementation\n",
    "incipit.run_similarity_search(edit_dist_metric='hamming')\n",
    "# run with experimental weighted Hamming distance implementation\n",
    "incipit.run_similarity_search(edit_dist_metric='weighted_hamming')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Done.\n",
      "Loading patterns...\n",
      "Done.\n",
      "Loading TF-IDF Cosine similarity matrix...\n",
      "Done.\n",
      "Running TF-IDF similarity search...\n",
      "              Cosine similarity\n",
      "NLB070089_01           0.107788\n",
      "NLB074769_02           0.092102\n",
      "NLB072311_01           0.085999\n",
      "NLB072883_01           0.083984\n",
      "NLB072559_01           0.078979\n"
     ]
    }
   ],
   "source": [
    "# initialize TFIDFSimilarity class instance to run 'TF-IDF' similarity search\n",
    "tfidf = TFIDFSimilarity(corpus_path=mtc_ann_corpus_path, level='duration_weighted', feature='diatonic_scale_degree')\n",
    "# select query tune\n",
    "tfidf.query_tune='NLB015569_01'\n",
    "# run search\n",
    "tfidf.run_similarity_search()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Outputs of all searches above can be found in subdirectories under '../mtc_ann_corpus/similarity_results/' root."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}