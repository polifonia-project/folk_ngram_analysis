{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583deeb9",
   "metadata": {},
   "source": [
    "# SIATEC Patterns and Tune Families in The Session\n",
    "\n",
    "### Abstract\n",
    "\n",
    "In this notebook we will run one of the best-known musical pattern extraction algorithms on tunes from *The Session*, and implement a simple method for the task of tune family detection (similar to the task of cover-song detection).\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "As already described (Polifonia deliverables D3.1-D3.6, 2021-2024; Danny Diamond MSc thesis, 2024), the concept of tune families is an important one in the musicology of traditional music, and we have developed methods of automatically detecting tune families based on several types of $n$-gram melodic patterns. The goal of this notebook is to implement another method, based on a totally different definition of melodic patterns. As we will see, this method does not work well -- not because of a weakness in the algorithms or the patterns, but because this new definition of pattern has a different goal -- *compression* rather than *linking*.\n",
    "\n",
    "\n",
    "### SIATEC patterns\n",
    "\n",
    "SIATEC, COSIATEC, and SIATECCompress are members of a family of pattern-extraction algorithms developed by David Meredith in multiple papers over several years. A representative paper is: [*COSIATEC and SIATECCompress:\n",
    "Pattern discovery by geometric compression*](https://vbn.aau.dk/en/publications/094ac3cf-78ca-4f87-8c6a-77303e3b1d36), David Meredith, Music Information Retrieval Evaluation eXchange (MIREX 2013).\n",
    "\n",
    "These algorithms work on *point-set* data, ie music where each note is represented only by an onset time (in beats, or MIDI ticks, or another unit) and a pitch (chromatic or diatonic). The algorithms work by detecting subsets of the data which occur more than once. They aim to extract the best subsets, which occur most often, using heuristics such as \"compactness\" of the pattern, to help. When detected, the pattern is removed from the dataset, and each repetition is replaced by a reference. Each repetition that is detected and encoded in such an extracted pattern thus allows the original dataset to be compressed.\n",
    "\n",
    "\n",
    "We focus in this notebook on the SIATECCompress algorithm, which allows patterns to overlap with each other. This choice is primarily because it is faster (Meredith, 2013) and our corpus is large.\n",
    "\n",
    "The implemention we use is `OMNISIA.jar`, from: http://www.titanmusic.com/software.php. We are grateful to David Meredith for providing a high-quality implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086c6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1254b8",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "We begin with the file [`thesession.abc`, available in GitHub](https://github.com/adactio/TheSession-data). For certainty and comparability, we host a specific dump under the Polifonia project:\n",
    "\n",
    "https://github.com/polifonia-project/folk_ngram_analysis/blob/master/FoNN/thesession_corpus/abc/thesession.abc\n",
    "\n",
    "We process this to MIDI files using `abc2midi.exe`, available from: https://ifdo.ca/~seymour/runabc/top.html \n",
    "\n",
    "In particular, https://ifdo.ca/~seymour/runabc/abcMIDI-2024.03.21.zip has `abc2midi.exe`.\n",
    "\n",
    "The command line we use is:\n",
    "\n",
    "`.\\abc2midi.exe thesession.abc -silent -NGRA -NCOM`\n",
    "\n",
    "This gives a `.mid` file for each tune in the `.abc` - approximately 40,000.\n",
    "\n",
    "We then run the SIATEC algorithm on each MIDI file as follows. We have a function to run the algorithm once for a single MIDI file and a function to loop over all MIDI files, and a function to parse the output of a single run to a new .pat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f430d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_patterns(lines):\n",
    "    '''parses a .SIATECCompress file or similar. each pattern is on a line by itself\n",
    "    in a format like:\n",
    "    \n",
    "    T(P(p(721,29),p(16081,29),p(31441,29),p(46801,29)),V(v(0,0),v(240,0),v(6480,2),v(7680,0),v(7920,0),v(9120,0),v(10320,2),v(10560,3),v(10800,4),v(11040,5),v(11280,6),v(11520,4),v(11760,3),v(12000,1),v(12240,2),v(12480,0),v(12720,-1),v(12960,-3),v(13200,-5),v(13440,-4),v(13680,-3),v(13920,-5),v(14160,-4)))\n",
    "\n",
    "    and we will convert to the following format:\n",
    "    \n",
    "    (pattern, n_occurrences, occurences, length, complexity)\n",
    "    \n",
    "    where:\n",
    "    \n",
    "    pattern is a list of (time, pitch) pairs, starting at (0, 0) because we translate for comparability\n",
    "    occurrences is a list of time values\n",
    "    n_occurrences is the length of that list\n",
    "    length is the number of pairs in pattern\n",
    "    complexity is the number of unique pitches in the pattern, divided by its length\n",
    "    \n",
    "    ([(0, 0), (15360, 0), (30720, 0), (46080, 0)], 23, [0, 240, 6480, 7680, 7920, 9120, 10320, 10560, 10800, 11040, 11280, 11520, 11760, 12000, 12240, 12480, 12720, 12960, 13200, 13440, 13680, 13920, 14160], 4, 0.25)\n",
    "\n",
    "    The MIDI time values look strange - but they are set algorithmically by abc2midi, \n",
    "    so corresponding notes should end up on corresponding time values.\n",
    "    '''\n",
    "    \n",
    "    # these little fns are to help eval() to parse a pattern line (output by OMNISIA) by itself\n",
    "    def T(P, V):\n",
    "        return P, V\n",
    "    def P(*ps):\n",
    "        return ps\n",
    "    def V(*vs):\n",
    "        return vs\n",
    "    def p(time, note):\n",
    "        return (time, note)\n",
    "    def v(time, note):\n",
    "        return (time, note)\n",
    "    for line in lines:\n",
    "        # each pattern is in a line by itself\n",
    "        # when we hit a blank line (length 1), there are no more patterns, so break\n",
    "        if len(line) == 1: break\n",
    "            \n",
    "        # otherwise parse line with eval\n",
    "        pattern, occurrences = eval(line)\n",
    "        \n",
    "        # we could set a threshold, ie minimum number of occurrences of pattern per tune,\n",
    "        # but we haven't done that in other work, so we will not do it here\n",
    "        # if len(occurrences) < 2: continue \n",
    "        \n",
    "        # some basic stats\n",
    "        length = len(pattern)\n",
    "        complexity = len(set(n[1] for n in pattern)) / length\n",
    "        \n",
    "        # we normalise patterns so that all patterns start at (0, 0)\n",
    "        # bearing in mind we use diatonic pitch.\n",
    "        time0, pitch0 = pattern[0]\n",
    "        pattern = [(pi[0] - time0, pi[1] - pitch0) for pi in pattern]\n",
    "        locations = [occ[0] for occ in occurrences]\n",
    "        #print('pattern', pattern)\n",
    "        #print('locations', locations)\n",
    "        #print('length', length)\n",
    "        #print('complexity', complexity)\n",
    "        \n",
    "        yield pattern, len(locations), locations, length, complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5cc2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_omnisia(filename, algo='SIATECCompress'):\n",
    "    '''algo can be SIATECCompress (faster, overlapping patterns) or COSIATEC'''\n",
    "    \n",
    "    # we have to munge the filenames a bit:\n",
    "    base = Path(filename).stem\n",
    "    sufx = Path(filename).suffixes[0][1:]\n",
    "    \n",
    "    if algo == 'SIATECCompress': suffix = 'SIATECCompress'\n",
    "    elif algo == 'COSIATEC': suffix = 'cos'\n",
    "    else: raise ValueError(algo)\n",
    "        \n",
    "    output = f'test/{base}-{sufx}/{base}-diat.{suffix}'\n",
    "\n",
    "    # -d true: morphetic (diatonic) pitch and so the filename below is 'diat', not 'chrom'\n",
    "    # -o test: output directory\n",
    "    # -nodate true: don't store date, avoid making unneeded directories\n",
    "    # -min 3: no patterns less than 3\n",
    "    cmd = f'java -Xmx1024M -jar OMNISIA.jar -a {algo} -d true -o test -nodate true -min 3 -i {filename}'.split(' ')\n",
    "    print('running OMNISIA, this may take a few seconds...')\n",
    "    subprocess.check_output(cmd)\n",
    "\n",
    "    # we read the log file:\n",
    "    # print('reading ' + output)\n",
    "    L = open(output).readlines()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b3c7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_omnisia_all(dirname):\n",
    "    '''loop over MIDI files, run OMNISIA, and read its output, and write to .pat file'''\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    failed = []\n",
    "    for midiname in os.listdir(dirname):\n",
    "        if not midiname.endswith('.mid'): continue\n",
    "        patternname = midiname.replace('.mid', '.pat')\n",
    "        \n",
    "        # only run if the output doesn't exist\n",
    "        # this is to help us run in batches, stop and restart\n",
    "        if Path(os.path.join(dirname, patternname)).is_file(): continue \n",
    "           \n",
    "        try:\n",
    "            print('trying', midiname)\n",
    "            L = run_omnisia(os.path.join(dirname, midiname))\n",
    "            f = open(os.path.join(dirname, patternname), 'w')\n",
    "            for pat in gather_patterns(L):\n",
    "                f.write(pat+'\\n')\n",
    "            f.close()\n",
    "        except:\n",
    "            # an exception can arise such as an out of heap space memory error\n",
    "            print(midiname, 'failed')\n",
    "            failed.append(midiname) # just pass, try this file again later\n",
    "        i += 1\n",
    "        print(f'{i}: {midiname}: time {time.time() - start:.1f}s')\n",
    "    return failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30088d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line below to run OMNISIA on all .mid files - this will take hours or days\n",
    "# failed = run_omnisia_all('thesession_dir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55ae3b",
   "metadata": {},
   "source": [
    "A small number of `.mid` files are not processed correctly. It's likely that a larger heap space or some pre-processing could solve this issue. For now we can ignore it, as the number is very small relative to the size of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d728f1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb3df7",
   "metadata": {},
   "source": [
    "Next we read all the pat files, parsing them into a single data structure. We have a function that works for a single output (from a single tune), and a function that loops over all tunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a16322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_pat_files(dirname, test_sample=None):\n",
    "    i = 0\n",
    "    d = {}\n",
    "    start = time.time()\n",
    "    for patternname in os.listdir(dirname):\n",
    "        if patternname.endswith('.pat'): \n",
    "            id = int(patternname[10:-4])\n",
    "            # print(patternname, id)\n",
    "            if id in d: continue\n",
    "            try:\n",
    "                d[id] = read_patterns(os.path.join(dirname, patternname))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            i += 1\n",
    "        if test_sample is not None and i > test_sample:\n",
    "            break\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90191406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patterns(filename):\n",
    "    \"\"\"Read a .pat file, which contains one pattern per line, already parsed\"\"\"\n",
    "    lines = open(filename).readlines()\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            # a hack - in an old version of the code we saved just (pattern, n_occurrences)\n",
    "            # but in the current version, we save (pattern, n_occurrences, occurrences, pattern_len, pattern_complexity)\n",
    "            # Only (pattern, n_occurrences) are needed for our current project. To avoid a large re-run\n",
    "            # we code this function to accept either format.\n",
    "            pattern, n_occurrences, occurrences, pattern_len, pattern_complexity = eval(line)\n",
    "        except:\n",
    "            pattern, n_occurrences = eval(line)\n",
    "        results.append((pattern, n_occurrences))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de0212",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment this line to read in all the .pat files to a data structure\n",
    "# d, failed = read_omnisia_outputs('thesession_dir')\n",
    "\n",
    "# and save to a pkl\n",
    "# f = open('data/thesession_omnisia_patterns.pkl', 'wb')\n",
    "# pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4cb52",
   "metadata": {},
   "source": [
    "Above, in two places, we have commented-out lines which launch large runs. Instead, for this notebook, the user can load the resulting data directly as a pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/thesession_omnisia_patterns.pkl', 'rb')\n",
    "d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da39c79",
   "metadata": {},
   "source": [
    "The pattern data is not very large in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0db0ada9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310800"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f0be4",
   "metadata": {},
   "source": [
    "### Part 2: using patterns for tune family detection\n",
    "\n",
    "Next, we can proceed to use our pattern data `d` for tune family detection.\n",
    "\n",
    "We begin with ground truth, a set of tune family annotations described by Danny Diamond (Deliverables D5.5-5.6, and MSc thesis, 2024). The tunes in these annotations are from The Session, so their patterns have already been processed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f5483c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = pd.read_csv('data/thesession_subset_metadata_with_tune_family_annotation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6d216",
   "metadata": {},
   "source": [
    "There are 315 members in 10 tune families:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "496e463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b6256b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blackbird',\n",
       " 'Drowsy Maggie',\n",
       " 'Gilderoy',\n",
       " \"Greig's Pipes\",\n",
       " 'Hob or Nob',\n",
       " \"Jenny's Welcome to Charlie\",\n",
       " 'Johnny Cope',\n",
       " \"Lord McDonald's\",\n",
       " \"O'Sullivan's March\",\n",
       " 'Road to Lisdoonvarna'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(annotated['tune_family'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019df24e",
   "metadata": {},
   "source": [
    "## Tune similarity via patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff9907ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pats(tune):\n",
    "    '''Given a tune represented by a list of (pattern, n_occurrences) values,\n",
    "    take only the non-trivial patterns and return them as a set.'''\n",
    "    s = set()\n",
    "    for pat, n_occurrences in tune:\n",
    "        # complexity = len(set(el[1] for el in pat)) / len(pat)\n",
    "        unique_notes = len(set(el[1] for el in pat))\n",
    "        if unique_notes > 1:\n",
    "            s.add(tuple(pat))\n",
    "    return s\n",
    "    \n",
    "def compare_patterns(tune_i, tune_j):\n",
    "    '''Check for an intersection among the non-trivial patterns of two tunes\n",
    "    (each represented by a list of (pattern, n_occurrences) values as above.)'''\n",
    "    pi = get_pats(tune_i)\n",
    "    pj = get_pats(tune_j)\n",
    "    intersect = pi.intersection(pj)\n",
    "    if intersect: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2ace9",
   "metadata": {},
   "source": [
    "Next we will go through all of the 315 annotated tune-family members, and for each of them\n",
    "we'll find which of the 40k The Session tunes it has any patterns in common with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ee90a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_ids = list(annotated['identifiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9231d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = defaultdict(list)\n",
    "k = 0\n",
    "for i in annotated_ids: # just the 315 annotated tune-family members\n",
    "    print(f'working on annotated id {i} ({k}/{len(annotated_ids)})')\n",
    "    for j in d: # all 40k The Session members\n",
    "        if i == j: continue\n",
    "        if compare_patterns(d[i], d[j]):\n",
    "            links[i].append(j)\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8335b",
   "metadata": {},
   "source": [
    "Next, our method is to calculate the degree of similarity as *intersection divided by union* (IOU) between two sets of patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbc07c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(s1, s2):\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c20ecd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iou_all():\n",
    "    iou = {}\n",
    "    for tune_i in annotated_ids:\n",
    "        pats_i = get_pats(d[tune_i])\n",
    "        for tune_j in links[tune_i]:\n",
    "            iou[(tune_i, tune_j)] = intersection_over_union(pats_i, get_pats(d[tune_j]))\n",
    "    return iou\n",
    "\n",
    "\n",
    "# as before we comment-out a long-running computation:\n",
    "# iou = run_iou_all()\n",
    "\n",
    "# after running that, we would save the IOU data to disk\n",
    "# f = open('data/thesession_annotated_omnisia_iou.pkl', 'wb')\n",
    "# pickle.dump(iou, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9535b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: in case you want to avoid running IOU, which takes some time, \n",
    "# you can instead load a dump of the IOU results as below:\n",
    "f = open('data/thesession_annotated_omnisia_iou.pkl', 'rb')\n",
    "iou = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85559664",
   "metadata": {},
   "source": [
    "Now we are ready to produce results and look at performance. For each tune in the ground-truth tune family annotations, we rank all of the other tunes in The Session which have any patterns in common.\n",
    "We rank them by IOU in decreasing order. Larger IOU values indicate higher similarity.\n",
    "\n",
    "We simply count how many of the top 10 in that ranking are correct, ie are in the same tune family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adee2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_results = {}\n",
    "for tune_i in annotated_ids:\n",
    "    sim = sorted([(iou[(tune_i, tune_j)], tune_j) for tune_j in links[tune_i]], reverse=True)\n",
    "    # print(sim)\n",
    "    hits = 0\n",
    "    for simval, tune_j in sim[:10]:\n",
    "        if tune_j in annotated_ids: # TODO is this correct?\n",
    "            hits += 1\n",
    "    hit_results[tune_i] = hits / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4df96",
   "metadata": {},
   "source": [
    "We see results are usually 0.0-0.3, ie 0-3 out of the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a4ddc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1029: 0.0,\n",
       " 14252: 0.1,\n",
       " 25163: 0.0,\n",
       " 27315: 0.1,\n",
       " 27316: 0.0,\n",
       " 27842: 0.1,\n",
       " 29508: 0.0,\n",
       " 39472: 0.0,\n",
       " 75: 0.1,\n",
       " 12552: 0.0,\n",
       " 12553: 0.1,\n",
       " 12554: 0.0,\n",
       " 12556: 0.1,\n",
       " 12557: 0.0,\n",
       " 12558: 0.0,\n",
       " 12559: 0.0,\n",
       " 12560: 0.0,\n",
       " 21434: 0.1,\n",
       " 23677: 0.1,\n",
       " 24548: 0.0,\n",
       " 24549: 0.0,\n",
       " 24681: 0.3,\n",
       " 25452: 0.0,\n",
       " 25695: 0.1,\n",
       " 26044: 0.0,\n",
       " 26249: 0.0,\n",
       " 29406: 0.1,\n",
       " 31921: 0.0,\n",
       " 35686: 0.1,\n",
       " 42137: 0.0,\n",
       " 29348: 0.1,\n",
       " 29515: 0.1,\n",
       " 31916: 0.0,\n",
       " 32702: 0.0,\n",
       " 1805: 0.2,\n",
       " 27795: 0.0,\n",
       " 33355: 0.0,\n",
       " 33356: 0.1,\n",
       " 36399: 0.0,\n",
       " 38698: 0.0,\n",
       " 2479: 0.1,\n",
       " 15787: 0.0,\n",
       " 35452: 0.0,\n",
       " 1104: 0.1,\n",
       " 1996: 0.0,\n",
       " 4101: 0.1,\n",
       " 4508: 0.0,\n",
       " 14355: 0.0,\n",
       " 14356: 0.1,\n",
       " 14357: 0.1,\n",
       " 15415: 0.0,\n",
       " 17110: 0.0,\n",
       " 17111: 0.0,\n",
       " 17112: 0.0,\n",
       " 24050: 0.0,\n",
       " 26494: 0.0,\n",
       " 27198: 0.0,\n",
       " 28174: 0.0,\n",
       " 28821: 0.1,\n",
       " 31201: 0.0,\n",
       " 32399: 0.0,\n",
       " 34225: 0.0,\n",
       " 36690: 0.1,\n",
       " 39782: 0.0,\n",
       " 27066: 0.0,\n",
       " 249: 0.0,\n",
       " 250: 0.2,\n",
       " 12965: 0.0,\n",
       " 12966: 0.2,\n",
       " 12967: 0.1,\n",
       " 12968: 0.1,\n",
       " 12969: 0.2,\n",
       " 12970: 0.1,\n",
       " 12971: 0.0,\n",
       " 12972: 0.2,\n",
       " 21776: 0.0,\n",
       " 25089: 0.2,\n",
       " 27843: 0.2,\n",
       " 32320: 0.2,\n",
       " 36691: 0.2,\n",
       " 36697: 0.0,\n",
       " 41930: 0.0,\n",
       " 2379: 0.0,\n",
       " 15726: 0.0,\n",
       " 21437: 0.0,\n",
       " 34622: 0.0,\n",
       " 10574: 0.0,\n",
       " 507: 0.0,\n",
       " 13430: 0.0,\n",
       " 13431: 0.5,\n",
       " 13432: 0.2,\n",
       " 13433: 0.0,\n",
       " 23658: 0.4,\n",
       " 27913: 0.0,\n",
       " 30618: 0.3,\n",
       " 38959: 0.0,\n",
       " 1075: 0.0,\n",
       " 14304: 0.1,\n",
       " 22684: 0.2,\n",
       " 24427: 0.1,\n",
       " 28608: 0.1,\n",
       " 30507: 0.2,\n",
       " 31614: 0.1,\n",
       " 32753: 0.0,\n",
       " 1729: 0.0,\n",
       " 5064: 0.0,\n",
       " 23964: 0.0,\n",
       " 30965: 0.0,\n",
       " 33566: 0.0,\n",
       " 10105: 0.0,\n",
       " 20222: 0.0,\n",
       " 20223: 0.2,\n",
       " 20224: 0.2,\n",
       " 2327: 0.1,\n",
       " 4953: 0.0,\n",
       " 15700: 0.0,\n",
       " 15701: 0.0,\n",
       " 15702: 0.0,\n",
       " 17346: 0.2,\n",
       " 25702: 0.1,\n",
       " 34131: 0.0,\n",
       " 40691: 0.1,\n",
       " 40702: 0.0,\n",
       " 41612: 0.0,\n",
       " 42095: 0.1,\n",
       " 16832: 0.1,\n",
       " 21469: 0.1,\n",
       " 35948: 0.3,\n",
       " 38611: 0.1,\n",
       " 1128: 0.0,\n",
       " 14388: 0.0,\n",
       " 553: 0.2,\n",
       " 13516: 0.2,\n",
       " 13517: 0.0,\n",
       " 20770: 0.0,\n",
       " 24821: 0.2,\n",
       " 30531: 0.0,\n",
       " 32089: 0.0,\n",
       " 2204: 0.0,\n",
       " 15569: 0.0,\n",
       " 15570: 0.0,\n",
       " 15571: 0.2,\n",
       " 15572: 0.0,\n",
       " 15573: 0.0,\n",
       " 15574: 0.0,\n",
       " 22666: 0.1,\n",
       " 22667: 0.1,\n",
       " 22668: 0.0,\n",
       " 25092: 0.2,\n",
       " 27381: 0.0,\n",
       " 32109: 0.0,\n",
       " 32487: 0.0,\n",
       " 34265: 0.1,\n",
       " 35995: 0.0,\n",
       " 40433: 0.0,\n",
       " 42104: 0.0,\n",
       " 22289: 0.1,\n",
       " 22296: 0.1,\n",
       " 3822: 0.0,\n",
       " 16754: 0.0,\n",
       " 29647: 0.0,\n",
       " 370: 0.2,\n",
       " 13179: 0.1,\n",
       " 13180: 0.0,\n",
       " 22961: 0.0,\n",
       " 24754: 0.0,\n",
       " 29604: 0.0,\n",
       " 33011: 0.1,\n",
       " 40380: 0.0,\n",
       " 5194: 0.0,\n",
       " 1424: 0.0,\n",
       " 1682: 0.1,\n",
       " 9850: 0.1,\n",
       " 24747: 0.0,\n",
       " 34293: 0.0,\n",
       " 41051: 0.1,\n",
       " 1272: 0.2,\n",
       " 14585: 0.0,\n",
       " 14586: 0.0,\n",
       " 22924: 0.1,\n",
       " 26779: 0.0,\n",
       " 40434: 0.1,\n",
       " 202: 0.0,\n",
       " 1357: 0.2,\n",
       " 12862: 0.0,\n",
       " 12863: 0.1,\n",
       " 12864: 0.1,\n",
       " 12865: 0.1,\n",
       " 14709: 0.2,\n",
       " 14710: 0.0,\n",
       " 24195: 0.0,\n",
       " 25776: 0.1,\n",
       " 27336: 0.0,\n",
       " 28852: 0.0,\n",
       " 29417: 0.0,\n",
       " 29543: 0.1,\n",
       " 31218: 0.1,\n",
       " 31925: 0.0,\n",
       " 33110: 0.0,\n",
       " 34110: 0.0,\n",
       " 37501: 0.0,\n",
       " 37509: 0.0,\n",
       " 41560: 0.0,\n",
       " 11942: 0.0,\n",
       " 27: 0.5,\n",
       " 12406: 0.0,\n",
       " 12407: 0.1,\n",
       " 12408: 0.2,\n",
       " 12409: 0.0,\n",
       " 12410: 0.0,\n",
       " 12411: 0.0,\n",
       " 12412: 0.0,\n",
       " 12413: 0.0,\n",
       " 12414: 0.1,\n",
       " 12415: 0.5,\n",
       " 20867: 0.0,\n",
       " 21232: 0.0,\n",
       " 23223: 0.1,\n",
       " 23242: 0.1,\n",
       " 23248: 0.0,\n",
       " 24826: 0.0,\n",
       " 27945: 0.5,\n",
       " 27946: 0.0,\n",
       " 29583: 0.0,\n",
       " 31098: 0.1,\n",
       " 31476: 0.3,\n",
       " 35491: 0.1,\n",
       " 37487: 0.1,\n",
       " 39017: 0.5,\n",
       " 39098: 0.0,\n",
       " 39125: 0.0,\n",
       " 787: 0.0,\n",
       " 13917: 0.0,\n",
       " 13918: 0.0,\n",
       " 13919: 0.0,\n",
       " 13920: 0.0,\n",
       " 13921: 0.1,\n",
       " 13922: 0.1,\n",
       " 30744: 0.0,\n",
       " 37408: 0.0,\n",
       " 6084: 0.0,\n",
       " 566: 0.0,\n",
       " 13540: 0.1,\n",
       " 13541: 0.0,\n",
       " 13542: 0.0,\n",
       " 13544: 0.0,\n",
       " 13545: 0.1,\n",
       " 31436: 0.0,\n",
       " 33252: 0.0,\n",
       " 33337: 0.0,\n",
       " 34784: 0.0,\n",
       " 39254: 0.1,\n",
       " 1627: 0.0,\n",
       " 11695: 0.0,\n",
       " 15048: 0.1,\n",
       " 15049: 0.0,\n",
       " 15050: 0.0,\n",
       " 21366: 0.0,\n",
       " 21425: 0.2,\n",
       " 29100: 0.1,\n",
       " 84: 0.1,\n",
       " 5846: 0.0,\n",
       " 12586: 0.0,\n",
       " 12587: 0.0,\n",
       " 12588: 0.1,\n",
       " 12589: 0.1,\n",
       " 12590: 0.0,\n",
       " 22215: 0.0,\n",
       " 22229: 0.0,\n",
       " 22230: 0.0,\n",
       " 34240: 0.1,\n",
       " 36242: 0.0,\n",
       " 38869: 0.0,\n",
       " 10561: 0.1,\n",
       " 32769: 0.1,\n",
       " 32770: 0.0,\n",
       " 36326: 0.0,\n",
       " 6643: 0.0,\n",
       " 18298: 0.0,\n",
       " 31326: 0.0,\n",
       " 2372: 0.1,\n",
       " 15719: 0.0,\n",
       " 21389: 0.0,\n",
       " 32737: 0.0,\n",
       " 41368: 0.0,\n",
       " 41369: 0.0,\n",
       " 42402: 0.0,\n",
       " 9639: 0.1,\n",
       " 20077: 0.2,\n",
       " 22351: 0.1,\n",
       " 26607: 0.1,\n",
       " 32647: 0.1,\n",
       " 605: 0.0,\n",
       " 13622: 0.0,\n",
       " 13623: 0.0,\n",
       " 13624: 0.0,\n",
       " 20783: 0.0,\n",
       " 20784: 0.0,\n",
       " 21375: 0.0,\n",
       " 21914: 0.0,\n",
       " 22923: 0.0,\n",
       " 23846: 0.0,\n",
       " 28229: 0.0,\n",
       " 31833: 0.0,\n",
       " 33362: 0.0,\n",
       " 33363: 0.1,\n",
       " 34044: 0.1,\n",
       " 41651: 0.0,\n",
       " 511: 0.1,\n",
       " 13438: 0.0,\n",
       " 13439: 0.0,\n",
       " 22807: 0.2,\n",
       " 22808: 0.2,\n",
       " 28196: 0.0,\n",
       " 30575: 0.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bae9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('data/thesession_annotated_omnisia_precision10_results.pkl', 'wb')\n",
    "#pickle.dump(hit_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46141d",
   "metadata": {},
   "source": [
    "We can compare the results (in text format, above) to the results achieved by Diamond (reported in Polifonia deliverables D5.5-5.6 and MSc thesis, 2024). Each result is effectively the number of 'hits' in the top 10 predictions, for a given query tune. As shown in the image below, the 'motif' method of Diamond sometimes gives a low result - 0 to 3 out of 10 - but often achieves values above 5 out of 10, never achieved using SIATEC patterns.\n",
    "\n",
    "![](img/motif_map_per_tune.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09df00",
   "metadata": {},
   "source": [
    "### Discussion and Conclusion\n",
    "\n",
    "Meredith (2013) writes:\n",
    "\"Both algorithms [COSIATEC and SIATECCompress] are founded on the hypothesis that the\n",
    "best ways of understanding a piece of music are those that\n",
    "are represented by the shortest descriptions of the piece. In\n",
    "other words, they are designed to explore the notion that\n",
    "music analysis is effectively just music compression.\"\n",
    "\n",
    "This hypothesis is central to my (McDermott) view of music analysis also. I look to papers such as Schmidhuber's *Low-Complexity Art*. In related work (working with Maziar Kanani and Se√°n O'Leary, not part of the Polifonia project), I use the *Assembly Pathway* (Cronin and colleagues) and the *Sequitur* algorithm (Nevil-Manning and Witten).\n",
    "\n",
    "However, it seems that a compression approach is not necessarily well-suited to the task of *linking pieces of music*. This difference in goals likely explains the unexpected results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdfdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
