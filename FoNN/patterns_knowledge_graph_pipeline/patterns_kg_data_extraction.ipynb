{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Polifonia [Patterns Knowledge Graph](https://github.com/polifonia-project/patterns-knowledge-graph) (KG) ingest pipeline. Step 1: Data extraction.\n",
    "\n",
    "This notebook uses FoNN to extract patterns, pattern occurrences and pattern locations from an input music corpus in feature sequence format, as outputted by ```../demo_notebooks/feature_extraction_demo.ipynb```.\n",
    "Any corpus for which a KG is being generated must first be processed via this notebook.\n",
    "\n",
    "This is the first of two FoNN KG preprocessing steps. Step two can be found in ```./patters_kg_data_processing.ipynb```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from FoNN.pattern_extraction import NgramPatternCorpus\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading input data: 100%|██████████| 315/315 [00:00<00:00, 1178.17it/s]\n",
      "Formatting data: 100%|██████████| 315/315 [00:00<00:00, 367921.40it/s]\n",
      "Reading input data:  42%|████▏     | 131/315 [00:00<00:00, 1302.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading input data: 100%|██████████| 315/315 [00:00<00:00, 1208.93it/s]\n",
      "Formatting data: 100%|██████████| 315/315 [00:00<00:00, 120361.28it/s]\n",
      "Reading input data: 100%|██████████| 315/315 [00:00<00:00, 1776.21it/s]\n",
      "Formatting data: 100%|██████████| 315/315 [00:00<00:00, 305551.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n",
      "Process completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set n_vals variable as tuple containing min and max pattern lengths for which patterns will be extracted\n",
    "n_vals = (4, 6)\n",
    "# Note: as above, maximum range is 4-6 pattern elements. If only a single pattern length is under investigation, the tuple still requires two elements, per (4, 4) for 4-element patterns.\n",
    "# Set musical feature under investigation. Default is 'diatonic_scale_degree'. A full list of feature names and explanations is available at ./README.md and in ../feature_sequence_extraction_tools.py top docstring.\n",
    "feature= 'diatonic_scale_degree'\n",
    "# set in path corresponding to the level of granularity of input corpus data under investigation -- this value can be either\n",
    "# 'note', 'accent' or 'duration_weighted' as discussed in FoNN README.md.\n",
    "in_path = '../mtc_ann_corpus/feature_sequence_data/duration_weighted'\n",
    "out_path = '../mtc_ann_corpus/kg_pipeline_input_data'\n",
    "\n",
    "# For each pattern length, create an NgramPatternCorpus object\n",
    "# Note: this differs from the standard FoNN ingest pipeline, which extracts patterns at all lengths via a single NgramPatternCorpus obj.\n",
    "\n",
    "_pattern_lengths = range(n_vals[0], n_vals[1] + 1)\n",
    "data = []\n",
    "for n in _pattern_lengths:\n",
    "    pattern_corpus = NgramPatternCorpus(in_dir=in_path, out_dir=out_path, feature=feature, n_vals=(n, n))\n",
    "    data.append(pattern_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus name: ground_truth_annotated_subset\n",
      "Level: accent-level\n",
      "Input directory: /Users/dannydiamond/NUIG/Polifonia/thesession/ground_truth_annotated_subset/feature_sequence_data/accent\n",
      "Corpus contains 315 tunes.\n",
      "Number of patterns extracted: 1768\n",
      "\n",
      "\n",
      "Corpus name: ground_truth_annotated_subset\n",
      "Level: accent-level\n",
      "Input directory: /Users/dannydiamond/NUIG/Polifonia/thesession/ground_truth_annotated_subset/feature_sequence_data/accent\n",
      "Corpus contains 315 tunes.\n",
      "Number of patterns extracted: 4168\n",
      "\n",
      "\n",
      "Corpus name: ground_truth_annotated_subset\n",
      "Level: accent-level\n",
      "Input directory: /Users/dannydiamond/NUIG/Polifonia/thesession/ground_truth_annotated_subset/feature_sequence_data/accent\n",
      "Corpus contains 315 tunes.\n",
      "Number of patterns extracted: 5901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a corpus-level pattern occurrences matrix for each n value (i.e.: for each patter length)\n",
    "for pattern_corpus in data:\n",
    "    pattern_corpus.create_pattern_frequency_matrix(write_output=False)\n",
    "    print(pattern_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              3822  37408  13541  35948  13623  13179  29583  30575  15050  \\\n",
      "patterns                                                                     \n",
      "[1, 1, 1, 1]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 2]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 3]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 4]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 5]   NaN    NaN    NaN    1.0    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "              38698  ...  17110  36690  27945  13438  14357  15049  34044  \\\n",
      "patterns             ...                                                    \n",
      "[1, 1, 1, 1]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 2]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 3]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 4]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 5]    NaN  ...    NaN    NaN    NaN    2.0    NaN    NaN    NaN   \n",
      "\n",
      "              26044  22961  31921  \n",
      "patterns                           \n",
      "[1, 1, 1, 1]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 2]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 3]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 4]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 5]    NaN    NaN    NaN  \n",
      "\n",
      "[5 rows x 315 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1768 entries, [1 1 1 1] to [7 7 7 7]\n",
      "Columns: 315 entries, 3822 to 31921\n",
      "dtypes: Sparse[float16, nan](315)\n",
      "memory usage: 70.0+ KB\n",
      "None\n",
      "                 3822  37408  13541  35948  13623  13179  29583  30575  15050  \\\n",
      "patterns                                                                        \n",
      "[1, 1, 1, 1, 1]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 2]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 3]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 4]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 5]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                 38698  ...  17110  36690  27945  13438  14357  15049  34044  \\\n",
      "patterns                ...                                                    \n",
      "[1, 1, 1, 1, 1]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 2]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 3]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 4]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 5]    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                 26044  22961  31921  \n",
      "patterns                              \n",
      "[1, 1, 1, 1, 1]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 2]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 3]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 4]    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 5]    NaN    NaN    NaN  \n",
      "\n",
      "[5 rows x 315 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4168 entries, [1 1 1 1 1] to [7 7 7 7 1]\n",
      "Columns: 315 entries, 3822 to 31921\n",
      "dtypes: Sparse[float16, nan](315)\n",
      "memory usage: 94.8+ KB\n",
      "None\n",
      "                    3822  37408  13541  35948  13623  13179  29583  30575  \\\n",
      "patterns                                                                    \n",
      "[1, 1, 1, 1, 1, 2]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 1, 3]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 1, 4]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 1, 7]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 2, 1]   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                    15050  38698  ...  17110  36690  27945  13438  14357  \\\n",
      "patterns                          ...                                      \n",
      "[1, 1, 1, 1, 1, 2]    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 1, 3]    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 1, 4]    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 1, 7]    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
      "[1, 1, 1, 1, 2, 1]    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                    15049  34044  26044  22961  31921  \n",
      "patterns                                               \n",
      "[1, 1, 1, 1, 1, 2]    NaN    NaN    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 1, 3]    NaN    NaN    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 1, 4]    NaN    NaN    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 1, 7]    NaN    NaN    NaN    NaN    NaN  \n",
      "[1, 1, 1, 1, 2, 1]    NaN    NaN    NaN    NaN    NaN  \n",
      "\n",
      "[5 rows x 315 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5901 entries, [1 1 1 1 1 2] to [7 7 7 7 1 1]\n",
      "Columns: 315 entries, 3822 to 31921\n",
      "dtypes: Sparse[float16, nan](315)\n",
      "memory usage: 113.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert pattern occurrences matrices to pandas DataFrames and write to file\n",
    "for idx, pattern_corpus in enumerate(data):\n",
    "    n = _pattern_lengths[idx]\n",
    "    pattern_corpus.convert_matrix_to_df(pattern_corpus.pattern_freq_matrix, write_output=True, filename=f\"{n}gram_patterns\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Run functions from pattern_locations.py to extract pattern locations data.\n",
    "# What we call 'locations' are the offset location or index of each pattern occurrence in the feature sequences\n",
    "# representing each tune in the corpus. For example, pattern [1 2 3 4] occurring in tune [1 2 3 4 5 1 2 3 4 5] will have\n",
    "# locations 0 and 5, representing the two indices at which the pattern's first element occurs in the tune sequence.\n",
    "\n",
    "# Note: The call below will automatically extract locations for all patterns between 4-6 elements in length, corresponding to\n",
    "# the range of pattern lengths defined above in 'n_vals' for which patterns were extracted.\n",
    "\n",
    "from FoNN.pattern_locations import *\n",
    "\n",
    "for n in _pattern_lengths:\n",
    "    results = {}\n",
    "    # call functions from FoNN.pattern_locations and run them:\n",
    "    in_files = read_file_paths(in_path)\n",
    "    for path in in_files:   # for all files in corpus\n",
    "        title = read_tune_title(path)                   # read titles\n",
    "        data = read_tune_data(path, feature)            # read feature sequence data\n",
    "        patterns = list(extract_patterns(data, n))      # extract n-gram patterns\n",
    "        locations = find_pattern_locations(patterns)    # calculate pattern locations\n",
    "        results[title] = dict(locations)                # return in nested dict per: {tune title: {pattern: locations}}\n",
    "\n",
    "    # store output as pickle file in out_path directory\n",
    "    f_name = f'{n}gram_locations.pkl'\n",
    "    locations_path = f\"{out_path}/{f_name}\"\n",
    "    with open(locations_path, 'wb') as f_out:\n",
    "        pickle.dump(results, f_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}